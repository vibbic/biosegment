{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"BioSegment \u00b6 BioSegment is a software stack to enable segmentation of microscopy data using machine learning models.","title":"Home"},{"location":"#biosegment","text":"BioSegment is a software stack to enable segmentation of microscopy data using machine learning models.","title":"BioSegment"},{"location":"admin-guide/setup/","text":"Setup \u00b6 Follow the instructions in the GitHub repo. README.md gives a general overview of the software stack and installation requirements. EXTRA_INFORMATION.md explains the software stack in more detail. It also contains notes on deploying the stack in a production environment. Edit the .env file with the configuration needed for your installation. A from scratch deployment on a basic Ubuntu server 20.04 LTS VM should have Docker , pip , docker-compose and pip install docker-auto-labels . Follow the documentation at https://dockerswarm.rocks/ . Edit the following script to suit your use case: bash scripts/start_swarm.sh Build the application TAG=prod FRONTEND_ENV=production bash ./scripts/build.sh Deploy the application DOMAIN=biosegment.ugent.be TRAEFIK_TAG=biosegment.ugent.be STACK_NAME=biosegment-ugent-be TAG=prod bash ./scripts/deploy.sh Note that there are two Traefik instances . For more information, see - Initial server configuration guides - Docker Swarm guide","title":"Setup"},{"location":"admin-guide/setup/#setup","text":"Follow the instructions in the GitHub repo. README.md gives a general overview of the software stack and installation requirements. EXTRA_INFORMATION.md explains the software stack in more detail. It also contains notes on deploying the stack in a production environment. Edit the .env file with the configuration needed for your installation. A from scratch deployment on a basic Ubuntu server 20.04 LTS VM should have Docker , pip , docker-compose and pip install docker-auto-labels . Follow the documentation at https://dockerswarm.rocks/ . Edit the following script to suit your use case: bash scripts/start_swarm.sh Build the application TAG=prod FRONTEND_ENV=production bash ./scripts/build.sh Deploy the application DOMAIN=biosegment.ugent.be TRAEFIK_TAG=biosegment.ugent.be STACK_NAME=biosegment-ugent-be TAG=prod bash ./scripts/deploy.sh Note that there are two Traefik instances . For more information, see - Initial server configuration guides - Docker Swarm guide","title":"Setup"},{"location":"admin-guide/user-managment/","text":"User Managment \u00b6 With an administrator account, extra interfaces are available in the frontend UI e.g. http://localhost/main/admin/users/all . Manage Users \u00b6 Here you can view all users and edit their profile. Clicking on the pencil will allow you to change their e-mail, deactivate the account and set a new password for the user. Create User \u00b6 Here you can add a new user with a valid e-mail account. If you make the user a superuser, they also gain administrator privileges. If the SMPT settings in .env are not in use or invalid, notify the user of their account credentials manually.","title":"User Managment"},{"location":"admin-guide/user-managment/#user-managment","text":"With an administrator account, extra interfaces are available in the frontend UI e.g. http://localhost/main/admin/users/all .","title":"User Managment"},{"location":"admin-guide/user-managment/#manage-users","text":"Here you can view all users and edit their profile. Clicking on the pencil will allow you to change their e-mail, deactivate the account and set a new password for the user.","title":"Manage Users"},{"location":"admin-guide/user-managment/#create-user","text":"Here you can add a new user with a valid e-mail account. If you make the user a superuser, they also gain administrator privileges. If the SMPT settings in .env are not in use or invalid, notify the user of their account credentials manually.","title":"Create User"},{"location":"contributing/contributing-guide/","text":"Contributing Guide \u00b6 You can contribute to BioSegment by making a GitHub Issue for a bug or feature proposal improving documentation, see Documentation guide contributing code, see Developer Guide","title":"Contributing Guide"},{"location":"contributing/contributing-guide/#contributing-guide","text":"You can contribute to BioSegment by making a GitHub Issue for a bug or feature proposal improving documentation, see Documentation guide contributing code, see Developer Guide","title":"Contributing Guide"},{"location":"contributing/documentation-guide/","text":"Documentation Guide \u00b6 Documentation of BioSegment is done through: This GitHub Pages site built using Material for MkDocs features a general overview, tutorial, User Guide, contribution guide and Developer Guide. Markdown files in the BioSegment repository e.g. README.md docstrings in the BioSegment source code the backend API OpenAPI/ReDoc documentation generated by FastAPI backend Add mkdocs documentation \u00b6 Via GitHub \u00b6 You can directly edit the documentation by clicking the pencil icon . This takes you to GitHub and lets you edit the documention's Markdown file located in /docs . Apply your changes and make a Pull request describing your change. Locally \u00b6 Setup your environment using the Material for MkDocs installation guide . Run a hot-reload server for the documentation and edit the files. conda env create -f environment_documentation.yaml --prune conda activate biosegment_documentation mkdocs serve When the changes are merged into main , the CI configuration will update the GitHub Pages site.","title":"Documentation Guide"},{"location":"contributing/documentation-guide/#documentation-guide","text":"Documentation of BioSegment is done through: This GitHub Pages site built using Material for MkDocs features a general overview, tutorial, User Guide, contribution guide and Developer Guide. Markdown files in the BioSegment repository e.g. README.md docstrings in the BioSegment source code the backend API OpenAPI/ReDoc documentation generated by FastAPI backend","title":"Documentation Guide"},{"location":"contributing/documentation-guide/#add-mkdocs-documentation","text":"","title":"Add mkdocs documentation"},{"location":"developer-guide/backend-development/","text":"Backend development \u00b6 The backend is implemented using FastAPI . Read their documentation and also those of Pydantic and SQLAlchemy. backend hot-reloads on file changes Database schema changes need the removal of the database volume Backend tests docker-compose exec backend bash /app/tests-start.sh Backend linting and formatting via docker bash docker-compose exec backend /app/format-imports.sh docker-compose exec backend /app/lint.sh locally bash cd backend/app poetry install poetry shell sh scripts/format-imports.sh sh scripts/lint.sh Structure \u00b6 backend/app/app/ schemas/ Pydantic schemas that define BioSegment data db/ contains configuration for the database and initial setup models/ SQLAlchemy models that define database table uses the schemas crud/ Python functions that implement database actions uses the models api/ endpoints that implement the API uses the schemas to define input/output type uses the crud actions","title":"Backend development"},{"location":"developer-guide/backend-development/#backend-development","text":"The backend is implemented using FastAPI . Read their documentation and also those of Pydantic and SQLAlchemy. backend hot-reloads on file changes Database schema changes need the removal of the database volume Backend tests docker-compose exec backend bash /app/tests-start.sh Backend linting and formatting via docker bash docker-compose exec backend /app/format-imports.sh docker-compose exec backend /app/lint.sh locally bash cd backend/app poetry install poetry shell sh scripts/format-imports.sh sh scripts/lint.sh","title":"Backend development"},{"location":"developer-guide/backend-development/#structure","text":"backend/app/app/ schemas/ Pydantic schemas that define BioSegment data db/ contains configuration for the database and initial setup models/ SQLAlchemy models that define database table uses the schemas crud/ Python functions that implement database actions uses the models api/ endpoints that implement the API uses the schemas to define input/output type uses the crud actions","title":"Structure"},{"location":"developer-guide/build-systems/","text":"Build systems \u00b6 BioSegment uses GitHub Actions to automate testing, linting and documentation updates. The configuration files are located in .github/ . Documentation \u00b6 The workflow .github/workflows/ci.yml rebuilds the documentation site when the main branch updates. The resulting site is published on the gh-pages branch. More documentation on publishing can be found here . Linting \u00b6 Testing \u00b6 Building images \u00b6 Local development \u00b6 For local development, act can be used. # install act curl https://raw.githubusercontent.com/nektos/act/master/install.sh | sudo bash Example commands: act -P ubuntu-latest=berombau/act_base -j test # WARNING act-environments-ubuntu:18.04 is >18GB! act -P ubuntu-latest=nektos/act-environments-ubuntu:18.04 -j lint Caveats There are differences between berombau/act_base and the GitHub images different oses are not supported public GitHub actions can depend on certain GitHub tooling, which would require incorporating that dependency in the act_base image.","title":"Build systems"},{"location":"developer-guide/build-systems/#build-systems","text":"BioSegment uses GitHub Actions to automate testing, linting and documentation updates. The configuration files are located in .github/ .","title":"Build systems"},{"location":"developer-guide/build-systems/#documentation","text":"The workflow .github/workflows/ci.yml rebuilds the documentation site when the main branch updates. The resulting site is published on the gh-pages branch. More documentation on publishing can be found here .","title":"Documentation"},{"location":"developer-guide/build-systems/#linting","text":"","title":"Linting"},{"location":"developer-guide/build-systems/#testing","text":"","title":"Testing"},{"location":"developer-guide/build-systems/#building-images","text":"","title":"Building images"},{"location":"developer-guide/build-systems/#local-development","text":"For local development, act can be used. # install act curl https://raw.githubusercontent.com/nektos/act/master/install.sh | sudo bash Example commands: act -P ubuntu-latest=berombau/act_base -j test # WARNING act-environments-ubuntu:18.04 is >18GB! act -P ubuntu-latest=nektos/act-environments-ubuntu:18.04 -j lint Caveats There are differences between berombau/act_base and the GitHub images different oses are not supported public GitHub actions can depend on certain GitHub tooling, which would require incorporating that dependency in the act_base image.","title":"Local development"},{"location":"developer-guide/code-generation/","text":"Code generation \u00b6 The backend API can be used to generate code for interfaces and Axios calls with openapi-generator download the latest API from http://localhost/api/v1/openapi.json and put it at frontend/openapi.json Run the following line to update the code at /frontend/api/generator/ . # in project directory docker run --rm -v $PWD:/local openapitools/openapi-generator-cli generate -i /local/openapi.json -g typescript-axios -o /local/frontend/src/api/generator/","title":"Code generation"},{"location":"developer-guide/code-generation/#code-generation","text":"The backend API can be used to generate code for interfaces and Axios calls with openapi-generator download the latest API from http://localhost/api/v1/openapi.json and put it at frontend/openapi.json Run the following line to update the code at /frontend/api/generator/ . # in project directory docker run --rm -v $PWD:/local openapitools/openapi-generator-cli generate -i /local/openapi.json -g typescript-axios -o /local/frontend/src/api/generator/","title":"Code generation"},{"location":"developer-guide/dash-frontend-development/","text":"Dash frontend development \u00b6 See Dash Python docs for more information. The dataset viewer is implemented using Plotly. Structure \u00b6 dash_frontend/app/ api/ Python implementation of the backend API assets/ custom CSS code components/ a Dash component has a unique id, a layout and decorated Python functions pages/ contains pages that import components index.py imports pages and routes them DatasetStore.py contains Datasets Dataset.py uses API to list backend data. Read file system based on location string in backend. Uses skimage.ImageCollection","title":"Dash frontend development"},{"location":"developer-guide/dash-frontend-development/#dash-frontend-development","text":"See Dash Python docs for more information. The dataset viewer is implemented using Plotly.","title":"Dash frontend development"},{"location":"developer-guide/dash-frontend-development/#structure","text":"dash_frontend/app/ api/ Python implementation of the backend API assets/ custom CSS code components/ a Dash component has a unique id, a layout and decorated Python functions pages/ contains pages that import components index.py imports pages and routes them DatasetStore.py contains Datasets Dataset.py uses API to list backend data. Read file system based on location string in backend. Uses skimage.ImageCollection","title":"Structure"},{"location":"developer-guide/frontend-development/","text":"Frontend development \u00b6 Install locally Node and npm Enter the frontend directory, install the NPM packages and start the live server using the npm scripts: cd frontend npm install npm run serve Then open your browser at http://localhost:8080 Notice that this live server is not running inside Docker, it is for local development, and that is the recommended workflow. Once you are happy with your frontend, you can build the frontend Docker image and start it, to test it in a production-like environment. But compiling the image at every change will not be as productive as running the local development server with live reload. Check the file package.json to see other available options. # unit test npm run unit:test # lint npm run lint If you have Vue CLI installed, you can also run vue ui to control, configure, serve, and analyze your application using a nice local web user interface. Structure \u00b6 frontend/src/ api/ code generated backend API components/ Vue components that use vuex store modules router/ routes views using vue-router views/ Uses components to create a webpage store/ Vuex store modules that contain state. Actions use the API. Vue \u00b6 The frontend is implemented in Vue. Read up on Vue, Typescript, vue-router, vuex, axios and Jest. Vuetify \u00b6 The frontend uses a Vue UI library named Vuetify . It features a list of ready-made components, see their documentation for more information. Adding a new feature \u00b6 Regenerate the backend API using code generation . Use new API feature by editing a module in the Vuex /store or creating a new one. create a new view in /views and add it to the /router . create a new component in /components that uses the new vuex module. add the new component to the new view. write a Jest test for the new code. Check if there are no Typescript errors. Lint.","title":"Frontend development"},{"location":"developer-guide/frontend-development/#frontend-development","text":"Install locally Node and npm Enter the frontend directory, install the NPM packages and start the live server using the npm scripts: cd frontend npm install npm run serve Then open your browser at http://localhost:8080 Notice that this live server is not running inside Docker, it is for local development, and that is the recommended workflow. Once you are happy with your frontend, you can build the frontend Docker image and start it, to test it in a production-like environment. But compiling the image at every change will not be as productive as running the local development server with live reload. Check the file package.json to see other available options. # unit test npm run unit:test # lint npm run lint If you have Vue CLI installed, you can also run vue ui to control, configure, serve, and analyze your application using a nice local web user interface.","title":"Frontend development"},{"location":"developer-guide/frontend-development/#structure","text":"frontend/src/ api/ code generated backend API components/ Vue components that use vuex store modules router/ routes views using vue-router views/ Uses components to create a webpage store/ Vuex store modules that contain state. Actions use the API.","title":"Structure"},{"location":"developer-guide/frontend-development/#vue","text":"The frontend is implemented in Vue. Read up on Vue, Typescript, vue-router, vuex, axios and Jest.","title":"Vue"},{"location":"developer-guide/frontend-development/#vuetify","text":"The frontend uses a Vue UI library named Vuetify . It features a list of ready-made components, see their documentation for more information.","title":"Vuetify"},{"location":"developer-guide/frontend-development/#adding-a-new-feature","text":"Regenerate the backend API using code generation . Use new API feature by editing a module in the Vuex /store or creating a new one. create a new view in /views and add it to the /router . create a new component in /components that uses the new vuex module. add the new component to the new view. write a Jest test for the new code. Check if there are no Typescript errors. Lint.","title":"Adding a new feature"},{"location":"developer-guide/setup/","text":"Setup \u00b6 The software code for BioSegment is published to the code repository GitHub . Follow the README for installation requirements and instructions.","title":"Setup"},{"location":"developer-guide/setup/#setup","text":"The software code for BioSegment is published to the code repository GitHub . Follow the README for installation requirements and instructions.","title":"Setup"},{"location":"developer-guide/workers/","text":"Workers \u00b6 Long-running tasks need to be delegated to workers. Celery is used to manage these. backend-worker \u00b6 Creates segmentations/annotations at the end of GPU worker task. GPU worker \u00b6 GPU support in docker-compose is very experimental, not working currently - see docker-compose_gpu.yml - docker-compose override gives errors, that's why one .yml file is needed - NVIDIA driver still isn't visible then, waiting for stable support Current workaround - expose rabbitMQ queue in docker-compose to host - run celery worker on host without virtualization cd gpu_worker # install environment for neuralnets celery worker conda env update -f celery_all_environment.yaml conda activate celery_neuralnets # On Linux bash start_worker.sh # On Windows set ROOT_DATA_FOLDER=X:/biosegment/data start_worker.bat # On Windows If force stopping the auto-reloading watchdog for workers (x2 Ctrl-C), some workers may linger. This will show up as warning when a new worker with the same name is started. View all host celery workers ps aux|grep 'celery worker' Kill them all ps auxww | grep 'celery worker' | awk '{print $2}' | xargs kill -9","title":"Workers"},{"location":"developer-guide/workers/#workers","text":"Long-running tasks need to be delegated to workers. Celery is used to manage these.","title":"Workers"},{"location":"developer-guide/workers/#backend-worker","text":"Creates segmentations/annotations at the end of GPU worker task.","title":"backend-worker"},{"location":"developer-guide/workers/#gpu-worker","text":"GPU support in docker-compose is very experimental, not working currently - see docker-compose_gpu.yml - docker-compose override gives errors, that's why one .yml file is needed - NVIDIA driver still isn't visible then, waiting for stable support Current workaround - expose rabbitMQ queue in docker-compose to host - run celery worker on host without virtualization cd gpu_worker # install environment for neuralnets celery worker conda env update -f celery_all_environment.yaml conda activate celery_neuralnets # On Linux bash start_worker.sh # On Windows set ROOT_DATA_FOLDER=X:/biosegment/data start_worker.bat # On Windows If force stopping the auto-reloading watchdog for workers (x2 Ctrl-C), some workers may linger. This will show up as warning when a new worker with the same name is started. View all host celery workers ps aux|grep 'celery worker' Kill them all ps auxww | grep 'celery worker' | awk '{print $2}' | xargs kill -9","title":"GPU worker"},{"location":"overview/data-folder/","text":"Data folder \u00b6 BioSegment works with datasets located in a ROOT_DATA_FOLDER folder, mostly a mounted network drive. Users can access the network drive directly to import or export files with their own tools and workflows. Structure \u00b6 ROOT_DATA_FOLDER setup.json JSON file containing configurations the backend reads during initialization of the database. Not required. Used in development. See the example at scripts/example_setup.json . EM/ {dataset_name} e.g. EMBL raw/ {pngs} models/ {model_name} e.g. unet_2d = output folder of neuralnets training saved model e.g. best_checkpoint.pytorch segmentations/ {dataset_name} labels/ = ground truth labels of the dataset {pngs} {segmentation_name} = output folder of neuralnets inference {pngs} annotations/ {dataset_name} {annotation_name} saved annotations e.g. annotations.json New dataset \u00b6 Adding a new dataset requires creating a folder with the dataset title in the EM/ folder e.g. {ROOT_DATA_FOLDER}/EM/{NEW_DATASET_NAME} . Then the dataset files need to be set in this folder e.g. a single .tiff or multiple .png files.","title":"Data folder"},{"location":"overview/data-folder/#data-folder","text":"BioSegment works with datasets located in a ROOT_DATA_FOLDER folder, mostly a mounted network drive. Users can access the network drive directly to import or export files with their own tools and workflows.","title":"Data folder"},{"location":"overview/data-folder/#structure","text":"ROOT_DATA_FOLDER setup.json JSON file containing configurations the backend reads during initialization of the database. Not required. Used in development. See the example at scripts/example_setup.json . EM/ {dataset_name} e.g. EMBL raw/ {pngs} models/ {model_name} e.g. unet_2d = output folder of neuralnets training saved model e.g. best_checkpoint.pytorch segmentations/ {dataset_name} labels/ = ground truth labels of the dataset {pngs} {segmentation_name} = output folder of neuralnets inference {pngs} annotations/ {dataset_name} {annotation_name} saved annotations e.g. annotations.json","title":"Structure"},{"location":"overview/data-folder/#new-dataset","text":"Adding a new dataset requires creating a folder with the dataset title in the EM/ folder e.g. {ROOT_DATA_FOLDER}/EM/{NEW_DATASET_NAME} . Then the dataset files need to be set in this folder e.g. a single .tiff or multiple .png files.","title":"New dataset"},{"location":"overview/getting-started/","text":"A BioSegment instance should be run using the instructions . The administrator of this instance can give you account credentials and a access URL e.g. https://biosegment.ugent.be . The default URL used in the documentation is localhost . Log in \u00b6 Open the URL in your webbrowser. This will direct you to a login interface. Use your account credentials to log in. Frontend interface \u00b6 Logging in will direct you to the BioSegment dashboard. Here you can manage projects, datasets, annotations and segmentations. For more information, follow the User Guide .","title":"Getting started"},{"location":"overview/getting-started/#log-in","text":"Open the URL in your webbrowser. This will direct you to a login interface. Use your account credentials to log in.","title":"Log in"},{"location":"overview/getting-started/#frontend-interface","text":"Logging in will direct you to the BioSegment dashboard. Here you can manage projects, datasets, annotations and segmentations. For more information, follow the User Guide .","title":"Frontend interface"},{"location":"overview/workflow/","text":"The following diagram gives on overview of the BioSegment workflow. Users interact with a frontend using their browser. They can visualize a dataset, edit annotations and create segmentations using AI models. The BioSegment backend handles the tasks given by the frontend and fetches the datasets from disk storage. For long-running tasks like conversion and fine-tuning, separate workers are used. Data \u00b6 Dataset Electron-microscopy data example formats: pngseq, tif3d Classes of interest example classes of interest: mitochondria, endoplasmatic reticulum... Segmentations Attribution for each part of a dataset to an interest mostly ground-truth or machine made Annotations Stroke or area of a part of the dataset that is attributed made by a human AI models able to take EM data and an annotation and create a segmentation can be pretrained and further fine-tuned with additional annotations e.g. UNet Actors \u00b6 Scientist A domain expert that wants to visualize and annotate EM data with a specialized tool AI engineer Implements and pretrains AI models User flow \u00b6 Example of the user flow for a scientist when interacting with a BioSegment frontend.","title":"Workflow"},{"location":"overview/workflow/#data","text":"Dataset Electron-microscopy data example formats: pngseq, tif3d Classes of interest example classes of interest: mitochondria, endoplasmatic reticulum... Segmentations Attribution for each part of a dataset to an interest mostly ground-truth or machine made Annotations Stroke or area of a part of the dataset that is attributed made by a human AI models able to take EM data and an annotation and create a segmentation can be pretrained and further fine-tuned with additional annotations e.g. UNet","title":"Data"},{"location":"overview/workflow/#actors","text":"Scientist A domain expert that wants to visualize and annotate EM data with a specialized tool AI engineer Implements and pretrains AI models","title":"Actors"},{"location":"overview/workflow/#user-flow","text":"Example of the user flow for a scientist when interacting with a BioSegment frontend.","title":"User flow"},{"location":"user-guide/backend-documentation/","text":"Backend documentation \u00b6 The BioSegment backend API is implemented using FastAPI . Documentation is automatically generated and available via a website on the instance. Their are two different documentation sites with different features. OpenAPI \u00b6 Available at localhost/docs . interactive interface ReDoc \u00b6 Available at localhost/redoc . no interactive interface supports some more advanced OpenAPIv3 features","title":"Backend documentation"},{"location":"user-guide/backend-documentation/#backend-documentation","text":"The BioSegment backend API is implemented using FastAPI . Documentation is automatically generated and available via a website on the instance. Their are two different documentation sites with different features.","title":"Backend documentation"},{"location":"user-guide/backend-documentation/#openapi","text":"Available at localhost/docs . interactive interface","title":"OpenAPI"},{"location":"user-guide/backend-documentation/#redoc","text":"Available at localhost/redoc . no interactive interface supports some more advanced OpenAPIv3 features","title":"ReDoc"},{"location":"user-guide/dashboard/","text":"Dashboard \u00b6 The frontend BioSegment UI allows you to view the current data in the backend and edit it through forms. The left navigation panel shows links to each backend item explained in the overview, e.g. projects, models... The admin interface is only available for users with superuser priviliges. See the Administrator Guide for more info. In Settings you can view or edit your user profile and change your account password. Editing a dataset description \u00b6 Click on Datasets in the navigation bar. Choose a default dataset e.g. EPFL . Click on the edit button with the pencil icon . Change the Description . Click Save . A green popup should confirm the update action. See the Tutorial for more information.","title":"Dashboard"},{"location":"user-guide/dashboard/#dashboard","text":"The frontend BioSegment UI allows you to view the current data in the backend and edit it through forms. The left navigation panel shows links to each backend item explained in the overview, e.g. projects, models... The admin interface is only available for users with superuser priviliges. See the Administrator Guide for more info. In Settings you can view or edit your user profile and change your account password.","title":"Dashboard"},{"location":"user-guide/dashboard/#editing-a-dataset-description","text":"Click on Datasets in the navigation bar. Choose a default dataset e.g. EPFL . Click on the edit button with the pencil icon . Change the Description . Click Save . A green popup should confirm the update action. See the Tutorial for more information.","title":"Editing a dataset description"},{"location":"user-guide/tutorial/","text":"Tutorial \u00b6 Run a segmentation on a new dataset \u00b6 Add a new dataset \u00b6 Create a folder with the dataset title at ROOT_DATA_FOLDER/EM/ . e.g. ROOT_DATA_FOLDER/EM/DATASET_TITLE . Create a folder titled raw in this new folder. Move the files (pngs/tiff) to the raw folder. pngs should be labeled {prefix}{index}.png , with index ranging from 0000 to e.g. 0049 for a dataset with resultion z = 50 . Note that indexing starts at 0. The prefix can be empty and should be the same for all files to ensure the sorted order. a tiff file should use the suffix .tif . A certain filename is not required. Navigate to the dataset create frontend e.g. http://localhost/main/datasets/create . Fill in the form and save choose file type pngseq for multiple png files and tif3d for a single tiff file. The resulution of the files can be obtained with e.g. Fiji Image > Show Info... . Width == x, Height == y and Depth == z. For pngseq , z is also equal to the number of png files. location = e.g. EM/DATASET_TITLE/raw/ . The dataset should show up in the list and be accessible by the viewer. Open the dataset in the viewer \u00b6 Navigate to http://localhost/dash/viewer . Use Selected dataset to show the new dataset. Run a segmentation using the correct model \u00b6 Use Selected model to pick the correct pretrained model. e.g. mito 2D when only mitochondria are a class of interest. Choose a descriptive segmentation. Click Start new segmentation . The loading bar should show success after <1min. View the generated segmentation \u00b6 Click the Refresh button at Selected segmentation in the Viewer. Selected the new segmentation with the dropdown. Access the files of the segmentation \u00b6 The segmentation should be visible using the frontend e.g. http://localhost/main/segmentations/all . In the edit dialogue, the location of the segmentation is visible. You can navigate to this folder on the network disk e.g. ROOT_DATA_FOLDER/segmentations/{DATASET_TITLE}/{SEGMENTATION_TITLE}/ . Add an external annotation to a dataset \u00b6 Create a folder at annotations/{DATASET_TITLE}/ with the annotation title e.g. ANNOTATION_TITLE . Add the annotation files to the folder Create a new annotation via the frontend e.g. http://localhost/main/annotations/create . location = e.g. annotations/{DATASET_TITLE}/ANNOTATION_FOLDER TODO type = ... To work from a previous annotation, duplicate the folder with a different name or reexport to a different folder from your external annotation tool. Then add it via the frontend as usual. Fine-tune a model with an annotation \u00b6 Create a new annotation \u00b6 Use the annotation tools or add an external annotation. Fine-tune a model using the created annotation \u00b6 In Fine-tune model select the model and annotation epochs = amount of iterations choose a new model name e.g. FINETUNED_MODEL_MITO Click Retrain model. The loading bar should show success after 10min-1h. Run a segmentation using the fine-tuned model \u00b6 Click refresh at Run segmentation > selected model. Select the model FINETUNED_MODEL_MITO , choose a new segmentation name and run. Now you can view the segmentation as shown in a different tutorial.","title":"Tutorial"},{"location":"user-guide/tutorial/#tutorial","text":"","title":"Tutorial"},{"location":"user-guide/tutorial/#run-a-segmentation-on-a-new-dataset","text":"","title":"Run a segmentation on a new dataset"},{"location":"user-guide/tutorial/#add-an-external-annotation-to-a-dataset","text":"Create a folder at annotations/{DATASET_TITLE}/ with the annotation title e.g. ANNOTATION_TITLE . Add the annotation files to the folder Create a new annotation via the frontend e.g. http://localhost/main/annotations/create . location = e.g. annotations/{DATASET_TITLE}/ANNOTATION_FOLDER TODO type = ... To work from a previous annotation, duplicate the folder with a different name or reexport to a different folder from your external annotation tool. Then add it via the frontend as usual.","title":"Add an external annotation to a dataset"},{"location":"user-guide/tutorial/#fine-tune-a-model-with-an-annotation","text":"","title":"Fine-tune a model with an annotation"},{"location":"user-guide/viewer/","text":"Viewer \u00b6 The viewer is an interface implemented using Dash . It can be used for basic visualizations of BioSegment data. The viewer also allows for annotating, running a segmentation job and fine-tuning a model. Open a dataset via the Dashboard or go to the URL directly e.g. http://localhost/dash/viewer . Use the refresh buttons to update the dropdowns with backend data. The viewer has 4 components. Viewer \u00b6 Given a dataset, segmentations and slider location, a view of a slice of the dataset will be shown. Differently annotated regions will be colored. the slider is the z coordinate. For the type pngseq , the slider value corresponds to the png filename e.g. slider value 25 shows the file 0025.png . Multiple segmentations can be selected at the same time. Annotations tools \u00b6 classes of interest e.g. mitochondria, ER determined by dataset Stroke width of the annotation brush Selected annotation Create a new annotation for given name when no annotation is selected, will create an empty annotation when an annotation is selected, will copy the annotation and give it the new name. Start editing current annotation The viewer will update with annotation tools when done, click on the done button to save the annotation. Only then will the annotation be saved in the backend. Run segmentation \u00b6 create a segmentation for currently selected dataset, given model and new segmentation name Fine-tune model \u00b6 create a new model from an existing model, given annotation and new model name. Epochs determines the amount of fine-tuning.","title":"Viewer"},{"location":"user-guide/viewer/#viewer","text":"The viewer is an interface implemented using Dash . It can be used for basic visualizations of BioSegment data. The viewer also allows for annotating, running a segmentation job and fine-tuning a model. Open a dataset via the Dashboard or go to the URL directly e.g. http://localhost/dash/viewer . Use the refresh buttons to update the dropdowns with backend data. The viewer has 4 components.","title":"Viewer"},{"location":"user-guide/viewer/#viewer_1","text":"Given a dataset, segmentations and slider location, a view of a slice of the dataset will be shown. Differently annotated regions will be colored. the slider is the z coordinate. For the type pngseq , the slider value corresponds to the png filename e.g. slider value 25 shows the file 0025.png . Multiple segmentations can be selected at the same time.","title":"Viewer"},{"location":"user-guide/viewer/#annotations-tools","text":"classes of interest e.g. mitochondria, ER determined by dataset Stroke width of the annotation brush Selected annotation Create a new annotation for given name when no annotation is selected, will create an empty annotation when an annotation is selected, will copy the annotation and give it the new name. Start editing current annotation The viewer will update with annotation tools when done, click on the done button to save the annotation. Only then will the annotation be saved in the backend.","title":"Annotations tools"},{"location":"user-guide/viewer/#run-segmentation","text":"create a segmentation for currently selected dataset, given model and new segmentation name","title":"Run segmentation"},{"location":"user-guide/viewer/#fine-tune-model","text":"create a new model from an existing model, given annotation and new model name. Epochs determines the amount of fine-tuning.","title":"Fine-tune model"}]}